"""
Constellation Question Generator

Backend logic for deciding IF and WHICH operators to target in follow-up questions.
Question content is generated by LLM (context-specific), not hardcoded archetypes.

ARCHITECTURE:
- Backend decides IF a question should be asked (should_ask_question)
- Backend decides WHICH operators to target (identify_pivot_operators + LLM Call 1's missing_operator_priority)
- Backend builds structured context (get_question_context)
- LLM generates the actual question text and options (in main.py generate_question_via_llm)
- User answers with selected option text
- LLM Call 1 re-runs on user's answer to extract actual operator values

SINGLE QUESTION MANDATE:
- ONE question maximum per response, or NONE
- If sufficient operators known for unity-separation diagnosis -> NO question
- If pivot operator missing -> ONE LLM-generated question
- NEVER ask 2, 3, 4, or more questions
"""

from typing import Dict, Any, List, Optional, Set, Tuple
from dataclasses import dataclass, field

# Import GoalContext from consciousness_state to avoid duplication
from consciousness_state import GoalContext

# Import canonical operator names from central source
from formulas import CANONICAL_OPERATOR_NAMES, SHORT_TO_CANONICAL

from logging_config import question_logger as logger


@dataclass
class MultiDimensionalQuestion:
    """Single question with LLM-generated contextual options"""
    question_id: str
    question_text: str  # LLM-generated, contextual to user's situation
    answer_options: Dict[str, str] = field(default_factory=dict)  # option_1..4 -> option text
    diagnostic_power: float = 0.0  # How much unity-separation clarity this provides
    target_operators: List[str] = field(default_factory=list)  # Which operators this question targets
    purposes_served: List[str] = field(default_factory=list)  # What this question accomplishes
    goal_context: GoalContext = field(default_factory=GoalContext)


# Use centralized canonical operator names
CORE_OPERATORS = CANONICAL_OPERATOR_NAMES

# Pivot operators by goal category - these are most diagnostic for unity-separation
CATEGORY_PIVOT_OPERATORS = {
    'achievement': ['At_attachment', 'F_fear', 'I_intention', 'S_surrender', 'W_witness'],
    'relationship': ['At_attachment', 'L_love', 'S_surrender', 'W_witness', 'F_fear'],
    'peace': ['R_resistance', 'S_surrender', 'W_witness', 'E_equanimity', 'F_fear'],
    'transformation': ['S_surrender', 'F_fear', 'W_witness', 'R_resistance', 'At_attachment'],
}


class ConstellationQuestionGenerator:
    """
    Generates single multi-dimensional question or None.
    Replaces entire old question generation system.
    """

    def __init__(self):
        self._question_counter = 0

    def parse_goal_context(
        self,
        query: str,
        detected_targets: List[str] = None
    ) -> GoalContext:
        """
        Extract goal category and emotional undertone from query.

        Args:
            query: User's original query text
            detected_targets: Targets detected by LLM Call 1 (optional)

        Returns:
            GoalContext with category, undertone, and domain
        """
        if detected_targets is None:
            detected_targets = []

        query_lower = query.lower()

        # Detect goal category
        if any(kw in query_lower for kw in [
            'revenue', 'profit', 'business', 'career', 'promotion',
            'success', 'achieve', 'goal', 'target', 'sales', 'growth',
            'market', 'company', 'startup', 'funding', 'investor'
        ]):
            category = 'achievement'
        elif any(kw in query_lower for kw in [
            'relationship', 'partner', 'marriage', 'family', 'connection',
            'love', 'dating', 'spouse', 'friend', 'intimacy', 'divorce',
            'children', 'parent', 'sibling'
        ]):
            category = 'relationship'
        elif any(kw in query_lower for kw in [
            'peace', 'calm', 'anxiety', 'stress', 'overthink', 'worry',
            'relax', 'quiet', 'still', 'nervous', 'panic', 'fear',
            'meditation', 'mindful', 'serene'
        ]):
            category = 'peace'
        elif any(kw in query_lower for kw in [
            'change', 'transform', 'reinvent', 'transition', 'shift',
            'move', 'quit', 'new', 'different', 'start over', 'pivot',
            'career change', 'relocate', 'rebrand'
        ]):
            category = 'transformation'
        else:
            category = 'achievement'  # Default

        # Detect emotional undertone
        if any(kw in query_lower for kw in [
            'urgent', 'desperate', 'need', 'must', 'have to', "can't",
            'help', 'emergency', 'critical', 'failing', 'dying'
        ]):
            undertone = 'urgency'
        elif any(kw in query_lower for kw in [
            'stuck', 'lost', "don't know", 'confused', 'unclear',
            'uncertain', 'maybe', 'might', 'could'
        ]):
            undertone = 'uncertainty'
        elif any(kw in query_lower for kw in [
            'curious', 'explore', 'wonder', 'interested', 'considering',
            'thinking about', 'what if', 'possible'
        ]):
            undertone = 'curiosity'
        elif any(kw in query_lower for kw in [
            'open', 'ready', 'willing', 'excited', 'looking forward'
        ]):
            undertone = 'openness'
        else:
            undertone = 'neutral'

        # Extract domain
        if any(kw in query_lower for kw in [
            'company', 'business', 'corporate', 'organization', 'team',
            'enterprise', 'firm', 'market', 'industry'
        ]):
            domain = 'business'
        elif any(kw in query_lower for kw in [
            'spiritual', 'consciousness', 'awakening', 'enlightenment',
            'meditation', 'dharma', 'karma', 'soul'
        ]):
            domain = 'spiritual'
        elif any(kw in query_lower for kw in [
            'health', 'body', 'physical', 'fitness', 'medical',
            'doctor', 'diet', 'exercise'
        ]):
            domain = 'health'
        else:
            domain = 'personal'

        gc = GoalContext(
            goal_text=query[:200],  # First 200 chars
            goal_category=category,
            emotional_undertone=undertone,
            domain=domain
        )
        logger.info(f"[QUESTION_GEN] Parsed goal: category={category} undertone={undertone} domain={domain}")
        return gc

    def identify_pivot_operators(
        self,
        goal_context: GoalContext,
        missing_operators: Set[str],
        known_operators: Dict[str, float]
    ) -> List[str]:
        """
        Identify which missing operators are most diagnostic for unity-separation.

        For this user's goal, which missing operator values would create
        maximum clarity on their unity-separation trajectory?

        Args:
            goal_context: Parsed goal context
            missing_operators: Set of operator names not yet known
            known_operators: Dict of known operator values

        Returns:
            List of pivot operator names
        """
        logger.debug(f"[identify_pivot_operators] category={goal_context.goal_category} missing={len(missing_operators)} known={len(known_operators)}")
        pivots = CATEGORY_PIVOT_OPERATORS.get(
            goal_context.goal_category,
            CATEGORY_PIVOT_OPERATORS['achievement']
        )

        # Return pivots that are actually missing
        missing_pivots = [op for op in pivots if op in missing_operators]

        logger.debug(f"[identify_pivot_operators] result: {len(missing_pivots)} missing pivots")
        return missing_pivots

    def calculate_diagnostic_power(
        self,
        goal_context: GoalContext,
        pivot_operators: List[str],
        known_operators: Dict[str, float]
    ) -> float:
        """
        Calculate diagnostic power of asking this question.

        Returns 0.0-1.0:
        - 1.0: Maximum clarity on unity-separation for this goal
        - 0.0: Minimal diagnostic value

        Args:
            goal_context: Parsed goal context
            pivot_operators: List of pivot operator names
            known_operators: Dict of known operator values

        Returns:
            Diagnostic power score
        """
        logger.debug(f"[calculate_diagnostic_power] pivots={len(pivot_operators)} known={len(known_operators)}")
        # If we already know the pivot operators, diagnostic power is low
        known_pivots = [op for op in pivot_operators if op in known_operators]
        if len(known_pivots) == len(pivot_operators):
            logger.debug("[calculate_diagnostic_power] result: 0.200 (all pivots known)")
            return 0.2  # Already know everything

        # If we're missing all pivot operators, diagnostic power is maximum
        missing_pivots = [op for op in pivot_operators if op not in known_operators]

        power = len(missing_pivots) / max(1, len(pivot_operators))

        # Boost for high-impact operators
        high_impact_ops = ['At_attachment', 'F_fear', 'S_surrender', 'W_witness', 'G_grace']
        high_impact_missing = [op for op in missing_pivots if op in high_impact_ops]

        if high_impact_missing:
            power *= 1.2

        result = min(1.0, power)
        logger.debug(f"[calculate_diagnostic_power] result: {result:.3f}")
        return result

    def should_ask_question(
        self,
        missing_operators: Set[str],
        known_operators: Dict[str, float],
        goal_context: GoalContext
    ) -> bool:
        """
        Determine if we should ask a question at all.

        Returns False if:
        - We already have sufficient operators for unity-separation diagnosis
        - Pivot operators are already known

        Args:
            missing_operators: Set of missing operator names
            known_operators: Dict of known operator values
            goal_context: Parsed goal context

        Returns:
            True if question should be asked
        """
        logger.debug(f"[should_ask_question] missing={len(missing_operators)} known={len(known_operators)}")
        pivot_ops = self.identify_pivot_operators(goal_context, missing_operators, known_operators)

        if not pivot_ops:
            # All pivot operators known
            logger.debug("[should_ask_question] result: False (all pivots known)")
            return False

        # Need at least 40% operator coverage for meaningful diagnosis without question
        coverage = len(known_operators) / len(CORE_OPERATORS)

        if coverage > 0.6 and len(pivot_ops) < 2:
            # High coverage and only 1 pivot missing - probably okay without question
            logger.debug(f"[should_ask_question] result: False (coverage={coverage:.3f} pivots_missing={len(pivot_ops)})")
            return False

        logger.debug(f"[should_ask_question] result: True (coverage={coverage:.3f} pivots_missing={len(pivot_ops)})")
        return True

    def get_question_context(
        self,
        goal_context: GoalContext,
        missing_operators: Set[str],
        known_operators: Dict[str, float],
        missing_operator_priority: List[str] = None,
        question_type: str = 'gap_filling'
    ) -> Optional[Dict[str, Any]]:
        """
        Build context for LLM-driven question generation.

        Backend decides IF to ask and WHICH operators to target.
        Returns structured context that the LLM caller uses to generate
        the actual question text and options.

        Returns None if no question should be asked.

        Args:
            goal_context: Parsed goal context
            missing_operators: Set of missing operator names
            known_operators: Dict of known operator values
            missing_operator_priority: LLM Call 1's opinion on most important missing operators
            question_type: 'gap_filling' or 'response_validation'

        Returns:
            Dict with question generation context, or None
        """
        # Backend decides IF to ask
        if question_type == 'gap_filling':
            if not self.should_ask_question(missing_operators, known_operators, goal_context):
                logger.info(f"[QUESTION_GEN] Skipping question: sufficient operators known ({len(known_operators)}/{len(CORE_OPERATORS)})")
                return None

        self._question_counter += 1
        logger.info(f"[QUESTION_GEN] Building context #{self._question_counter} type={question_type} category={goal_context.goal_category}")

        # Backend decides WHICH operators to target
        pivot_ops = self.identify_pivot_operators(goal_context, missing_operators, known_operators)
        diagnostic_power = self.calculate_diagnostic_power(goal_context, pivot_ops, known_operators)

        # Combine pivot operators with LLM's priority list for comprehensive targeting
        target_operators = list(pivot_ops)
        if missing_operator_priority:
            for op in missing_operator_priority:
                canonical = SHORT_TO_CANONICAL.get(op, op)
                if canonical in missing_operators and canonical not in target_operators:
                    target_operators.append(canonical)

        # Human-readable descriptions for LLM prompt
        operator_descriptions = {
            'Psi_consciousness': 'overall consciousness quality',
            'K_karma': 'accumulated karma / past action patterns',
            'M_maya': 'illusion / gap between perception and reality',
            'G_grace': 'grace / openness to receiving support',
            'W_witness': 'witness awareness / ability to observe without reacting',
            'A_aware': 'awareness / present-moment clarity',
            'P_presence': 'presence / energetic aliveness',
            'E_equanimity': 'equanimity / emotional balance',
            'V_void': 'void tolerance / comfort with uncertainty',
            'L_love': 'love / capacity for unconditional connection',
            'R_resistance': 'resistance / friction against what is',
            'At_attachment': 'attachment / clinging to outcomes',
            'Av_aversion': 'aversion / pushing away discomfort',
            'Se_seva': 'seva / service orientation',
            'Ce_cleaning': 'cleaning / purification practice',
            'Su_suffering': 'suffering / relationship with pain',
            'As_aspiration': 'aspiration / growth drive',
            'F_fear': 'fear / relationship with threat',
            'De_desire': 'desire / wanting patterns',
            'Re_resistance': 'active resistance / pushing against change',
            'Hf_habit_force': 'habit force / strength of automatic patterns',
            'Sa_samskara': 'samskara / deep impressions from past',
            'Bu_buddhi': 'buddhi / discriminative intelligence',
            'Ma_manas': 'manas / mind activity level',
            'Ch_chitta': 'chitta / consciousness field clarity',
            'I_intention': 'intention / clarity of purpose',
            'S_surrender': 'surrender / letting go capacity',
            'Co_coherence': 'coherence / inner alignment',
            'Tr_trust': 'trust / basic trust in life',
            'O_openness': 'openness / receptivity to new experience',
            'J_joy': 'joy / innate happiness',
        }

        target_descriptions = []
        for op in target_operators[:10]:  # Top 10 most important
            desc = operator_descriptions.get(op, op)
            target_descriptions.append(f"{op}: {desc}")

        purposes = [
            'context_understanding',    # Understand user's inner experience
            'operator_extraction',      # Enable LLM Call 1 to extract missing operators
            's_level_refinement',       # Refine consciousness level estimate
            'gap_closing',              # Close gaps in calculated values
        ]
        if question_type == 'response_validation':
            purposes = [
                'response_validation',      # Validate articulated insights
                'operator_extraction',      # Extract remaining missing operators
                'accuracy_assessment',      # Assess response accuracy
            ]

        context = {
            'question_id': f"{'constellation' if question_type == 'gap_filling' else 'validation'}_{self._question_counter}",
            'question_type': question_type,
            'goal_context': goal_context,
            'target_operators': target_operators,
            'target_descriptions': target_descriptions,
            'missing_count': len(missing_operators),
            'known_count': len(known_operators),
            'diagnostic_power': diagnostic_power,
            'purposes_served': purposes,
        }

        logger.info(
            f"[QUESTION_GEN] Context built: id={context['question_id']} "
            f"diagnostic_power={diagnostic_power:.2f} targets={len(target_operators)} "
            f"missing={len(missing_operators)}"
        )
        return context


# Factory function
def create_question_generator() -> ConstellationQuestionGenerator:
    """Create constellation question generator instance"""
    return ConstellationQuestionGenerator()
