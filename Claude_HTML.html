<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Reality Transformer - Test Client</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Arial, sans-serif;
      background: #0a0a0a;
      color: #e0e0e0;
      padding: 20px;
      line-height: 1.6;
    }
    
    .container {
      max-width: 1200px;
      margin: 0 auto;
    }
    
    header {
      margin-bottom: 30px;
      border-bottom: 1px solid #333;
      padding-bottom: 20px;
    }
    
    h1 {
      font-size: 28px;
      font-weight: 600;
      margin-bottom: 8px;
    }
    
    .subtitle {
      color: #888;
      font-size: 14px;
    }
    
    .input-section {
      background: #141414;
      border: 1px solid #2a2a2a;
      border-radius: 12px;
      padding: 24px;
      margin-bottom: 20px;
    }
    
    textarea {
      width: 100%;
      min-height: 120px;
      background: #0a0a0a;
      border: 1px solid #333;
      border-radius: 8px;
      padding: 16px;
      color: #e0e0e0;
      font-size: 15px;
      font-family: inherit;
      resize: vertical;
    }
    
    textarea:focus {
      outline: none;
      border-color: #4a9eff;
    }
    
    .controls {
      display: flex;
      gap: 12px;
      align-items: center;
      margin-top: 16px;
    }
    
    button {
      padding: 12px 24px;
      border: none;
      border-radius: 8px;
      font-size: 15px;
      font-weight: 500;
      cursor: pointer;
      transition: all 0.2s;
    }
    
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
    
    .btn-primary {
      background: #4a9eff;
      color: white;
    }
    
    .btn-primary:hover:not(:disabled) {
      background: #3a8eef;
    }
    
    .btn-secondary {
      background: #2a2a2a;
      color: #e0e0e0;
    }
    
    .btn-secondary:hover:not(:disabled) {
      background: #3a3a3a;
    }
    
    .status {
      color: #888;
      font-size: 14px;
      display: flex;
      align-items: center;
      gap: 8px;
    }
    
    .status.active {
      color: #4a9eff;
    }
    
    .status.error {
      color: #ff4a4a;
    }
    
    .status.success {
      color: #4aff88;
    }
    
    .spinner {
      width: 14px;
      height: 14px;
      border: 2px solid #333;
      border-top-color: #4a9eff;
      border-radius: 50%;
      animation: spin 0.8s linear infinite;
    }
    
    @keyframes spin {
      to { transform: rotate(360deg); }
    }
    
    .output-section {
      background: #141414;
      border: 1px solid #2a2a2a;
      border-radius: 12px;
      padding: 24px;
      min-height: 400px;
    }
    
    .output-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 16px;
      padding-bottom: 12px;
      border-bottom: 1px solid #2a2a2a;
    }
    
    .output-title {
      font-size: 16px;
      font-weight: 500;
    }
    
    .metrics {
      display: flex;
      gap: 20px;
      font-size: 13px;
      color: #888;
    }
    
    .metric {
      display: flex;
      flex-direction: column;
      align-items: flex-end;
    }
    
    .metric-label {
      font-size: 11px;
      text-transform: uppercase;
      letter-spacing: 0.5px;
    }
    
    .metric-value {
      color: #4a9eff;
      font-weight: 500;
    }
    
    #output {
      white-space: pre-wrap;
      word-wrap: break-word;
      line-height: 1.7;
      font-size: 15px;
    }
    
    .empty-state {
      color: #666;
      text-align: center;
      padding: 60px 20px;
      font-size: 14px;
    }
    
    .examples {
      margin-top: 12px;
      display: flex;
      gap: 8px;
      flex-wrap: wrap;
    }
    
    .example-chip {
      background: #1a1a1a;
      border: 1px solid #2a2a2a;
      padding: 6px 12px;
      border-radius: 6px;
      font-size: 13px;
      cursor: pointer;
      transition: all 0.2s;
    }
    
    .example-chip:hover {
      background: #2a2a2a;
      border-color: #3a3a3a;
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>Reality Transformer</h1>
      <p class="subtitle">Consciousness-Based Transformation Engine • Test Client</p>
    </header>

    <div class="input-section">
      <textarea 
        id="prompt" 
        placeholder="Enter your transformation query...&#10;&#10;Example: I am Nirma. I want to become market leader."
      ></textarea>
      
      <div class="examples">
        <div class="example-chip" onclick="setExample(0)">Market Leadership</div>
        <div class="example-chip" onclick="setExample(1)">Career Transition</div>
        <div class="example-chip" onclick="setExample(2)">Product Strategy</div>
      </div>
      
      <div class="controls">
        <button id="runBtn" class="btn-primary" onclick="runQuery()">
          Run Deep Excavation
        </button>
        <button id="stopBtn" class="btn-secondary" onclick="stopQuery()" disabled>
          Stop
        </button>
        <div id="status" class="status"></div>
      </div>
    </div>

    <div class="output-section">
      <div class="output-header">
        <div class="output-title">Response</div>
        <div class="metrics">
          <div class="metric">
            <div class="metric-label">Time to First Token</div>
            <div class="metric-value" id="ttft">—</div>
          </div>
          <div class="metric">
            <div class="metric-label">Total Time</div>
            <div class="metric-value" id="totalTime">—</div>
          </div>
          <div class="metric">
            <div class="metric-label">Tokens</div>
            <div class="metric-value" id="tokenCount">0</div>
          </div>
        </div>
      </div>
      <div id="output" class="empty-state">
        Your transformation response will appear here...
      </div>
    </div>
  </div>

  <script>
    const examples = [
      "I am Nirma. I want to become market leader in the detergent space.",
      "I'm a software engineer at Google. I want to transition into AI safety research within 18 months.",
      "We're launching a B2B SaaS product in a crowded CRM market. How do we position for rapid growth?"
    ];

    let eventSource = null;
    let startTime = null;
    let firstTokenTime = null;
    let tokenCount = 0;

    function setExample(index) {
      document.getElementById('prompt').value = examples[index];
    }

    function setStatus(text, type = '') {
      const statusEl = document.getElementById('status');
      statusEl.className = `status ${type}`;
      
      if (type === 'active') {
        statusEl.innerHTML = `<div class="spinner"></div>${text}`;
      } else {
        statusEl.textContent = text;
      }
    }

    function updateMetric(id, value) {
      document.getElementById(id).textContent = value;
    }

    function formatTime(ms) {
      if (ms < 1000) return `${ms}ms`;
      return `${(ms / 1000).toFixed(1)}s`;
    }

    async function runQuery() {
      const prompt = document.getElementById('prompt').value.trim();
      if (!prompt) {
        setStatus('Please enter a query', 'error');
        return;
      }

      // Reset state
      document.getElementById('output').textContent = '';
      document.getElementById('output').className = '';
      startTime = Date.now();
      firstTokenTime = null;
      tokenCount = 0;
      updateMetric('ttft', '—');
      updateMetric('totalTime', '—');
      updateMetric('tokenCount', '0');

      // Update UI
      document.getElementById('runBtn').disabled = true;
      document.getElementById('stopBtn').disabled = false;
      setStatus('Initializing...', 'active');

      // Start SSE stream
      const encodedPrompt = encodeURIComponent(prompt);
      eventSource = new EventSource(`/api/run?prompt=${encodedPrompt}`);

      eventSource.addEventListener('status', (e) => {
        const data = JSON.parse(e.data);
        setStatus(data.message, 'active');
      });

      eventSource.addEventListener('token', (e) => {
        const data = JSON.parse(e.data);
        
        // Record first token time
        if (!firstTokenTime) {
          firstTokenTime = Date.now();
          const ttft = firstTokenTime - startTime;
          updateMetric('ttft', formatTime(ttft));
        }

        // Append token
        const outputEl = document.getElementById('output');
        outputEl.textContent += data.text;
        tokenCount++;
        updateMetric('tokenCount', tokenCount);

        // Update total time
        const elapsed = Date.now() - startTime;
        updateMetric('totalTime', formatTime(elapsed));
      });

      eventSource.addEventListener('done', (e) => {
        const totalTime = Date.now() - startTime;
        updateMetric('totalTime', formatTime(totalTime));
        setStatus(`Completed in ${formatTime(totalTime)}`, 'success');
        cleanup();
      });

      eventSource.addEventListener('error', (e) => {
        console.error('SSE Error:', e);
        setStatus('Connection error - see console', 'error');
        cleanup();
      });

      eventSource.onerror = () => {
        setStatus('Stream error - check backend connection', 'error');
        cleanup();
      };
    }

    function stopQuery() {
      if (eventSource) {
        eventSource.close();
        setStatus('Stopped by user', 'error');
        cleanup();
      }
    }

    function cleanup() {
      if (eventSource) {
        eventSource.close();
        eventSource = null;
      }
      document.getElementById('runBtn').disabled = false;
      document.getElementById('stopBtn').disabled = true;
    }

    // Keyboard shortcut: Cmd/Ctrl + Enter to run
    document.getElementById('prompt').addEventListener('keydown', (e) => {
      if ((e.metaKey || e.ctrlKey) && e.key === 'Enter') {
        e.preventDefault();
        if (!document.getElementById('runBtn').disabled) {
          runQuery();
        }
      }
    });
  </script>
</body>
</html>
```

---

## **Backend Stack Architecture**
```
┌─────────────────────────────────────────────────────────────┐
│                         FRONTEND                             │
│  HTML Test Client (SSE streaming, metrics, stop controls)   │
└────────────────────────────┬────────────────────────────────┘
                             │ HTTPS
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                    VERCEL (Gateway)                          │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  Next.js API Route: /api/run                         │   │
│  │  • Receives prompt via SSE GET request               │   │
│  │  • Step 1: Call OpenAI GPT-5.2 (parse context)      │   │
│  │  • Step 2: Call Inference Service (OOF math)         │   │
│  │  • Step 3: Call OpenAI GPT-5.2 (deep narration)     │   │
│  │  • Streams tokens back to client                     │   │
│  └──────────────────────────────────────────────────────┘   │
└────────────────────────────┬────────────────────────────────┘
                             │ HTTP/gRPC
                             ▼
┌─────────────────────────────────────────────────────────────┐
│              INFERENCE SERVICE (Fly.io / AWS)                │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  Rust Service (or C++)                               │   │
│  │  • Loads compiled OOF registry at startup            │   │
│  │  • Endpoint: POST /inference                         │   │
│  │  • Input: Evidence JSON                              │   │
│  │  • Process: Full tier execution + uncertainty        │   │
│  │  • Output: Posteriors JSON                           │   │
│  └──────────────────────────────────────────────────────┘   │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  Redis (in-memory cache)                             │   │
│  │  • Preloaded registry/graph                          │   │
│  │  • Session state (if multi-turn)                     │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                   OFFLINE BUILD STEP                         │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  Formula Compiler (Python/Node script)               │   │
│  │  • Input: OOF.txt (1,100 text formulas)              │   │
│  │  • Output: registry.json + graph.bin                 │   │
│  │  • Runs at deploy time, not per request              │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│                      STORAGE LAYER                           │
│  • PostgreSQL (Vercel Postgres or AWS RDS)                   │
│    - Store run history, outputs, debugging traces            │
│  • S3 (optional)                                              │
│    - Large artifacts, backups                                │
└─────────────────────────────────────────────────────────────┘
```

---

## **Backend File Structure**
```
reality-transformer/
├── frontend/                    # Vercel deployment
│   ├── public/
│   │   └── test.html           # The HTML file above
│   ├── pages/
│   │   └── api/
│   │       └── run.ts          # SSE streaming endpoint
│   ├── lib/
│   │   ├── openai.ts           # OpenAI client wrapper
│   │   └── inference-client.ts # HTTP client to inference service
│   ├── package.json
│   └── vercel.json
│
├── inference-service/          # Separate repo/container
│   ├── src/
│   │   ├── main.rs             # HTTP server (Axum/Actix)
│   │   ├── registry.rs         # Load compiled registry
│   │   ├── graph.rs            # Dependency graph
│   │   ├── inference.rs        # Tier execution + belief propagation
│   │   └── types.rs            # Data structures
│   ├── artifacts/
│   │   ├── registry.json       # Generated by compiler
│   │   └── graph.bin           # Precomputed dependency matrix
│   ├── Cargo.toml
│   └── Dockerfile
│
└── formula-compiler/           # Build-time tool
    ├── compile.py              # Parse OOF.txt → registry.json
    ├── validate.py             # Verify no circular deps, missing nodes
    └── requirements.txt
```

---

## **API Contracts**

### **1. Frontend → Vercel**
```
GET /api/run?prompt={user_query}
Response: text/event-stream (SSE)

Events:
  event: status
  data: {"message": "Parsing context..."}

  event: token
  data: {"text": "Based on your "}

  event: done
  data: {}

  event: error
  data: {"message": "Inference timeout"}
```

### **2. Vercel → OpenAI (Parse)**
```
POST https://api.openai.com/v1/chat/completions
{
  "model": "gpt-5.2-turbo",
  "messages": [{
    "role": "system",
    "content": "Extract structured evidence from user goals. Return ONLY JSON."
  }, {
    "role": "user",
    "content": "I am Nirma. I want to become market leader."
  }],
  "temperature": 0,
  "max_tokens": 500
}

Response:
{
  "user_identity": "Nirma",
  "goal": "become market leader",
  "observations": [
    {"var": "Ambition", "value": 0.82, "confidence": 0.85},
    {"var": "TimeHorizon", "value": "12-24m", "confidence": 0.6}
  ],
  "targets": ["MarketLeadershipPath", "Bottlenecks", "NextActions"]
}
```

### **3. Vercel → Inference Service**
```
POST https://inference.yourapp.com/run
{
  "evidence": { /* parsed JSON from step 1 */ },
  "targets": ["MarketLeadershipPath", "Bottlenecks", "NextActions"],
  "config": {
    "max_iterations": 100,
    "convergence_threshold": 0.001
  }
}

Response:
{
  "posteriors": {
    "MarketLeadershipPath": {"mean": 0.61, "variance": 0.08},
    "Bottlenecks": [
      {"name": "Positioning", "weight": 0.32},
      {"name": "Distribution", "weight": 0.24}
    ],
    "NextActions": [
      {"action": "Narrow market wedge", "confidence": 0.74, "urgency": 0.88}
    ]
  },
  "metadata": {
    "runtime_ms": 58231,
    "converged": true,
    "iterations": 47
  }
}
```

### **4. Vercel → OpenAI (Narrate)**
```
POST https://api.openai.com/v1/chat/completions
{
  "model": "gpt-5.2-turbo",
  "messages": [{
    "role": "system",
    "content": "You are Reality Transformer. Narrate transformation insights from structured analysis. Be deep, articulate, actionable."
  }, {
    "role": "user",
    "content": "Original query: I am Nirma. I want to become market leader.\n\nAnalysis results: {posteriors JSON}"
  }],
  "stream": true,
  "temperature": 0.7,
  "max_tokens": 4000
}

Response: SSE stream of tokens